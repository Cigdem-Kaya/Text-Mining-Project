{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1385d229-e04e-4e3f-9ba0-aeb3e0257543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import des librairies\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from unidecode import unidecode \n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re\n",
    "import langid \n",
    "nltk.download('stopwords')\n",
    "import simplemma\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a70c9c9-ca96-4966-88cd-a20b0a106e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(482803, 5)\n",
      "Date           datetime64[ns, UTC]\n",
      "Contenu                     object\n",
      "Retweet                      int64\n",
      "Hashtags                    object\n",
      "utilisateur                 object\n",
      "dtype: object\n",
      "                            Date  \\\n",
      "0      2022-10-15 23:56:38+00:00   \n",
      "1      2022-10-15 23:52:53+00:00   \n",
      "2      2022-10-15 23:49:40+00:00   \n",
      "3      2022-10-15 23:47:44+00:00   \n",
      "4      2022-10-15 23:47:17+00:00   \n",
      "...                          ...   \n",
      "482798 2022-02-01 01:38:34+00:00   \n",
      "482799 2022-02-01 01:08:39+00:00   \n",
      "482800 2022-02-01 00:37:04+00:00   \n",
      "482801 2022-02-01 00:32:09+00:00   \n",
      "482802 2022-02-01 00:20:38+00:00   \n",
      "\n",
      "                                                  Contenu  Retweet  \\\n",
      "0       Cependant, le milliardaire aurait proposé un a...        0   \n",
      "1       BREAKING ! Face au recul de l'armée russe en #...        0   \n",
      "2       [Ukraine] Comment en est-on arrivé là ? Résumé...        0   \n",
      "3       Mais le ministre rajoute \" nous ne sommes pas ...        3   \n",
      "4       @KalustD @Guillaume_Bigot @CNEWS @jchribuisson...        0   \n",
      "...                                                   ...      ...   \n",
      "482798  #UKRAINE – CONSEIL DE SÉCURITÉ.\\nRéunion sous ...        1   \n",
      "482799  (La Provence): #Ukraine: #Moscou et Washington...        0   \n",
      "482800  @EpochOpinion Les forces gouvernementales ukra...        0   \n",
      "482801  On a du mal à sortir de son rôle de maire de P...        1   \n",
      "482802  @LauMi72 @vpecresse D'un autre côté #Macron il...        0   \n",
      "\n",
      "                                                 Hashtags     utilisateur  \n",
      "0                                ['NoovoInfo', 'Ukraine']       NoovoInfo  \n",
      "1       ['Ukraine', 'Poutine', 'Russie', 'BlockedByAra...     kongratieff  \n",
      "2       ['Histoire', 'Ukraine', 'OTAN', 'UnionEuropéen...        Se7h_Bzh  \n",
      "3                        ['poutine', 'russie', 'ukraine']  DjSOFlaRECETTE  \n",
      "4       ['Russie', 'Poutine', 'Caucase', 'Ukraine', 'g...     ChVanetzian  \n",
      "...                                                   ...             ...  \n",
      "482798                                        ['UKRAINE']        gnbasile  \n",
      "482799                              ['Ukraine', 'Moscou']    titrespresse  \n",
      "482800                                ['Kiev', 'Ukraine']     Crollalanza  \n",
      "482801                            ['facepalm', 'Ukraine']          vlentz  \n",
      "482802                      ['Macron', 'Ukraine', 'Mali']    KasperBeskid  \n",
      "\n",
      "[482803 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "## Insertion des données et vérification\n",
    "df=pd.read_csv('df.csv')\n",
    "df=pd.DataFrame(df,columns=['Date','Contenu','Retweet','Hashtags','utilisateur'])\n",
    "df['Date']=pd.to_datetime(df['Date'])\n",
    "print(df.shape)\n",
    "print(df.dtypes)\n",
    "print(df[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e60c2e55-4443-4e48-8b26-821831c9fde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fr    471716\n",
      "Name: langue, dtype: int64\n",
      "(471716, 7)\n"
     ]
    }
   ],
   "source": [
    "#mise en place d'un classifieur de langue et mise en place sur notre dataframe\n",
    "langue=[langid.classify(doc) for doc in df['Contenu']]\n",
    "dflang=pd.DataFrame(langue, columns=['langue','score'])\n",
    "df=pd.concat([df,dflang],axis=1)\n",
    "df=df[df['langue']=='fr']\n",
    "print(df['langue'].value_counts())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c01a05e9-9fde-407d-b33a-ede8171e6454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2441/2230237101.py:5: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  df['Contenu'][:5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    cependant, le milliardaire aurait propose un a...\n",
       "1    breaking ! face au recul de l'armee russe en #...\n",
       "2    [ukraine] comment en est-on arrive la ? resume...\n",
       "3    mais le ministre rajoute \" nous ne sommes pas ...\n",
       "4    @kalustd @guillaume_bigot @cnews @jchribuisson...\n",
       "Name: Contenu, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Traitement du corpus \n",
    "df['Contenu']=[str(doc) for doc in df['Contenu']]\n",
    "df['Contenu']=[doc.lower() for doc in df['Contenu']]\n",
    "df['Contenu']=[unidecode(doc) for doc in df['Contenu']]\n",
    "df['Contenu'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56cdcfcc-a0a5-483d-aa65-f323efd8e6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2441/1950498021.py:5: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  df['Contenu'][:5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    cependant le milliardaire aurait propose un au...\n",
       "1    breaking face au recul de l armee russe en ukr...\n",
       "2     ukraine comment en est on arrive la resume de...\n",
       "3    mais le ministre rajoute nous ne sommes pas en...\n",
       "4     kalustd guillaume bigot cnews jchribuisson lo...\n",
       "Name: Contenu, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Traitement des années et suppression des caracères spéciaux +suppression des URL.\n",
    "df['Contenu']=[re.sub(r'[0-9]{4}','<annee>',doc) for doc in df['Contenu']]\n",
    "df['Contenu']=[re.sub(r'[^a-z<>]+',' ',doc) for doc in df['Contenu']]\n",
    "df['Contenu']=[re.sub(r'http*\\S+', ' ', doc) for doc in df['Contenu']]\n",
    "df['Contenu'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dda09f-314f-4954-8584-5fd840f39911",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Insertion, traitement et suppression des stop_words en francais\n",
    "stop_words=stopwords.words('french')\n",
    "stop_words=[unidecode(sw) for sw in stop_words]\n",
    "df['Contenu']=[' '.join([word for word in doc.split() if word not in stop_words]) for doc in df['Contenu']]\n",
    "df['Contenu'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8c349f-f68a-41bd-97d2-e06f98b04ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualisation de la fréquence d'apparition des mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b203a297-a809-4192-be95-b0cc890db977",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=df['Contenu']\n",
    "words=' '.join(corpus)\n",
    "words_list=words.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4082964c-eb25-4cfd-8363-987eee05a2b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "freq=defaultdict(int)\n",
    "\n",
    "for mot in words_list:\n",
    "    freq[mot] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e32528-3216-49ab-ab7e-de68927bdf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "least=[ k for k in freq.keys()if freq[k]>6000] \n",
    "print (f\" Voici la liste des mots avec une occurence > à 10000 : \\n {least}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1091799-e53a-48c0-be3b-26e978d2b306",
   "metadata": {},
   "outputs": [],
   "source": [
    "least=[ k for k in freq.keys()if freq[k]>12000] \n",
    "print (f\" Voici la liste des mots avec une occurence > à 10000 : \\n {least}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d77d65-7c8c-4a5b-9fa2-6193490a697b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1aa0bb3-6431-4b49-a4a6-a1b105bc8560",
   "metadata": {},
   "source": [
    "La lémmatisation à une conservation du sens des mots plus élevé, dans notre projet on cherche à effectuer du topics modelling donc à\n",
    "extraire des topics repprésentant au mieux les informations du corpus, c'est pourquoion choisis la lemmatisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24da2a2-6e96-4982-98bb-1c19fa57b3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lémmatisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d36b16f-c4fd-4742-97ae-4c96b8974462",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[' '.join([simplemma.lemmatize(word,lang='fr') for word in doc.split()]) for doc in corpus]\n",
    "corpus[20:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e17fe5c-8116-47a9-97ae-d6e8d41cd1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755fe028-7839-41e1-8ea1-ebe2a415f692",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calcul de la taille du vocabulaire de corpus lemmatisé.\n",
    "words=' '.join(corpus)\n",
    "words_list=words.split()\n",
    "vocab=list(set(words_list))\n",
    "print(f\"la taille du vocab est de : {len(vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b676ad4-b2e4-40ff-af76-c5b98c2d923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calcul de la taille du vocabulaire non lemmatisé. \n",
    "words=' '.join(df['Contenu'])\n",
    "words_list=words.split()\n",
    "vocab=list(set(words_list))\n",
    "print(f\"la taille du vocab est de : {len(vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b3b1ee-2084-434a-80c5-1b014ebe5656",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extraction des données lemmatisé.\n",
    "df_lemm=pd.DataFrame(corpuslemm,columns=['Contenu'])\n",
    "df_lemm.to_csv('df_lemm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e65dfb2-3a00-4250-b581-3629d4228c95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
